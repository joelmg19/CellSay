{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOiO6zKEX4Vh6zf1zNSlAne"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a17TzHBae8sW","executionInfo":{"status":"ok","timestamp":1763215328452,"user_tz":180,"elapsed":12404,"user":{"displayName":"HARRY ALBETH RUIZ IPARRAGUIRRE","userId":"09082086999302081748"}},"outputId":"da12d324-903c-49b9-85f1-901493f90e24"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.3.228-py3-none-any.whl.metadata (37 kB)\n","Collecting roboflow\n","  Downloading roboflow-1.2.11-py3-none-any.whl.metadata (9.7 kB)\n","Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n","Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from roboflow) (2025.10.5)\n","Collecting idna==3.7 (from roboflow)\n","  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n","Requirement already satisfied: cycler in /usr/local/lib/python3.12/dist-packages (from roboflow) (0.12.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.4.9)\n","Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n","  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n","Collecting pi-heif<2 (from roboflow)\n","  Downloading pi_heif-1.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.5 kB)\n","Collecting pillow-avif-plugin<2 (from roboflow)\n","  Downloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.9.0.post0)\n","Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.2.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.17.0)\n","Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.5.0)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from roboflow) (4.67.1)\n","Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.0.0)\n","Collecting filetype (from roboflow)\n","  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n","Downloading ultralytics-8.3.228-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading roboflow-1.2.11-py3-none-any.whl (89 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pi_heif-1.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl (4.2 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n","Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n","Installing collected packages: pillow-avif-plugin, filetype, pi-heif, opencv-python-headless, idna, ultralytics-thop, roboflow, ultralytics\n","  Attempting uninstall: opencv-python-headless\n","    Found existing installation: opencv-python-headless 4.12.0.88\n","    Uninstalling opencv-python-headless-4.12.0.88:\n","      Successfully uninstalled opencv-python-headless-4.12.0.88\n","  Attempting uninstall: idna\n","    Found existing installation: idna 3.11\n","    Uninstalling idna-3.11:\n","      Successfully uninstalled idna-3.11\n","Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pi-heif-1.1.1 pillow-avif-plugin-1.5.2 roboflow-1.2.11 ultralytics-8.3.228 ultralytics-thop-2.0.18\n"]}],"source":["!pip install ultralytics roboflow\n"]},{"cell_type":"code","source":["from roboflow import Roboflow\n","rf = Roboflow(api_key=\"CjWCT39rcsdEwhXojlUj\")\n","project = rf.workspace(\"mtrharry\").project(\"reconocimiento-dinero-clp-o-usd-a93dk\")\n","version = project.version(2)\n","dataset = version.download(\"yolov8\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gPiqHGCafKmS","executionInfo":{"status":"ok","timestamp":1763176334876,"user_tz":180,"elapsed":23367,"user":{"displayName":"HARRY ALBETH RUIZ IPARRAGUIRRE","userId":"09082086999302081748"}},"outputId":"60a68922-7301-45d8-f8ac-17b1c3f14093"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loading Roboflow workspace...\n","loading Roboflow project...\n"]},{"output_type":"stream","name":"stderr","text":["Downloading Dataset Version Zip in Reconocimiento-dinero-clp-o-USD-2 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 786239/786239 [00:10<00:00, 72286.79it/s]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\n","Extracting Dataset Version Zip to Reconocimiento-dinero-clp-o-USD-2 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22756/22756 [00:05<00:00, 3960.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Creating new Ultralytics Settings v0.0.6 file âœ… \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Th3JB56MgB_B","executionInfo":{"status":"ok","timestamp":1763176386206,"user_tz":180,"elapsed":27340,"user":{"displayName":"HARRY ALBETH RUIZ IPARRAGUIRRE","userId":"09082086999302081748"}},"outputId":"877551d7-13be-4930-ad61-4849a56c2208"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","\n","save_dir = \"/content/drive/MyDrive/YOLO_DineroCLP\"\n","os.makedirs(save_dir, exist_ok=True)\n","\n","save_dir\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"nBEopuY_gG-U","executionInfo":{"status":"ok","timestamp":1763176386565,"user_tz":180,"elapsed":363,"user":{"displayName":"HARRY ALBETH RUIZ IPARRAGUIRRE","userId":"09082086999302081748"}},"outputId":"ec6a6cdf-c1b8-4692-9655-cabddc84f20a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/YOLO_DineroCLP'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["!ls\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BGGP5bgkg_Es","executionInfo":{"status":"ok","timestamp":1763176609187,"user_tz":180,"elapsed":135,"user":{"displayName":"HARRY ALBETH RUIZ IPARRAGUIRRE","userId":"09082086999302081748"}},"outputId":"5a84674a-cbc9-4cb3-9e93-97936116c52f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["drive  Reconocimiento-dinero-clp-o-USD-2  sample_data  yolov8n.pt\n"]}]},{"cell_type":"code","source":["from ultralytics import YOLO\n","\n","model = YOLO(\"yolov8n.pt\")\n","\n","results = model.train(\n","    data=\"Reconocimiento-dinero-clp-o-USD-2/data.yaml\",\n","    epochs=50,\n","    imgsz=640,\n","    batch=16,\n","    device=0,\n","    project=\"/content/drive/MyDrive/YOLODinero\",\n","    name=\"entrenamiento_billetes\",\n","    save_period=5\n",")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V3VAO9CjgKL9","executionInfo":{"status":"ok","timestamp":1763185554725,"user_tz":180,"elapsed":8927285,"user":{"displayName":"HARRY ALBETH RUIZ IPARRAGUIRRE","userId":"09082086999302081748"}},"outputId":"790d6460-3b6a-4629-e724-cf8b802654bc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.228 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=Reconocimiento-dinero-clp-o-USD-2/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=entrenamiento_billetes2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/YOLODinero, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/YOLODinero/entrenamiento_billetes2, save_frames=False, save_json=False, save_period=5, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 24.0MB/s 0.0s\n","Overriding model.yaml nc=80 with nc=11\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    753457  ultralytics.nn.modules.head.Detect           [11, [64, 128, 256]]          \n","Model summary: 129 layers, 3,012,993 parameters, 3,012,977 gradients, 8.2 GFLOPs\n","\n","Transferred 319/355 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 91.9MB/s 0.1s\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1942.3Â±737.6 MB/s, size: 70.7 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Reconocimiento-dinero-clp-o-USD-2/train/labels... 10374 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 10374/10374 2.3Kit/s 4.6s\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Reconocimiento-dinero-clp-o-USD-2/train/labels.cache\n","WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 5674, len(boxes) = 10507. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 649.9Â±457.1 MB/s, size: 72.3 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Reconocimiento-dinero-clp-o-USD-2/valid/labels... 624 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 624/624 757.9it/s 0.8s\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Reconocimiento-dinero-clp-o-USD-2/valid/labels.cache\n","WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 532, len(boxes) = 638. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n","Plotting labels to /content/drive/MyDrive/YOLODinero/entrenamiento_billetes2/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/content/drive/MyDrive/YOLODinero/entrenamiento_billetes2\u001b[0m\n","Starting training for 50 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       1/50       2.1G      0.597      2.402      1.186         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.6it/s 3:02\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.6it/s 5.5s\n","                   all        624        638      0.618      0.656      0.695      0.629\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       2/50      2.58G     0.5584      1.342      1.133         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.7it/s 2:53\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.3it/s 6.0s\n","                   all        624        638      0.784      0.777       0.84      0.747\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       3/50       2.6G     0.5553       1.08      1.124         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.7it/s 2:53\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.9it/s 5.1s\n","                   all        624        638      0.873      0.787      0.901      0.807\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       4/50      2.61G     0.5402     0.9295      1.112         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.7it/s 2:55\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 4.1it/s 4.9s\n","                   all        624        638      0.928       0.86      0.959      0.875\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       5/50      2.63G     0.5185     0.8323      1.098         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.8it/s 2:52\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.5it/s 5.8s\n","                   all        624        638      0.957      0.924      0.971        0.9\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       6/50      2.65G     0.4977     0.7508      1.087         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.8it/s 2:51\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.2it/s 6.2s\n","                   all        624        638      0.899      0.932      0.972      0.898\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       7/50      2.67G     0.4841     0.6969      1.077         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.8it/s 2:50\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.8it/s 5.2s\n","                   all        624        638      0.928      0.901      0.965      0.909\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       8/50      2.68G     0.4705     0.6563      1.067         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.8it/s 2:52\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.9it/s 5.2s\n","                   all        624        638      0.964      0.937      0.983      0.929\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       9/50       2.7G     0.4674      0.622      1.067         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.8it/s 2:52\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.2it/s 6.2s\n","                   all        624        638      0.954       0.92      0.969       0.92\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      10/50      2.71G      0.449     0.6023      1.055         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.8it/s 2:51\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.9it/s 5.2s\n","                   all        624        638      0.923      0.965      0.981       0.93\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      11/50      2.74G     0.4503       0.59      1.056         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.8it/s 2:52\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.1it/s 6.5s\n","                   all        624        638      0.976      0.953      0.984      0.938\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      12/50      2.75G     0.4416     0.5644      1.049         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.8it/s 2:53\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.8it/s 5.3s\n","                   all        624        638      0.987      0.946      0.987      0.942\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      13/50      2.77G     0.4319     0.5485      1.045         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.8it/s 2:53\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.9it/s 5.1s\n","                   all        624        638      0.965      0.953      0.982      0.933\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      14/50      2.78G     0.4261     0.5327       1.04         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.7it/s 2:53\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.1it/s 6.5s\n","                   all        624        638      0.966      0.954      0.982      0.938\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      15/50       2.8G     0.4174     0.5173      1.035         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.8it/s 2:52\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 4.4it/s 4.6s\n","                   all        624        638      0.966       0.96       0.98      0.937\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      16/50      2.82G     0.4129     0.5075      1.034         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.8it/s 2:50\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.5it/s 5.7s\n","                   all        624        638      0.988      0.958      0.989      0.948\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      17/50      2.84G     0.4098     0.4959      1.029         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.8it/s 2:51\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 4.2it/s 4.8s\n","                   all        624        638      0.978      0.966      0.987      0.951\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      18/50      2.85G     0.4037     0.4839      1.023         18        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.7it/s 2:57\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 4.0it/s 5.0s\n","                   all        624        638       0.96      0.961       0.98      0.948\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      19/50      2.87G     0.4037     0.4771      1.023         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.6it/s 2:59\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 4.2it/s 4.8s\n","                   all        624        638      0.972      0.973      0.986      0.953\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      20/50      2.89G     0.4014     0.4706      1.023         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.7it/s 2:54\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.7it/s 5.4s\n","                   all        624        638      0.977      0.967      0.987      0.954\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      21/50      2.91G     0.3922     0.4568      1.019         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.7it/s 2:56\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.2it/s 6.3s\n","                   all        624        638      0.984      0.972       0.99      0.956\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      22/50      2.92G     0.3879     0.4529      1.016         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.7it/s 2:55\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 4.0it/s 5.0s\n","                   all        624        638      0.972      0.966      0.988      0.954\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      23/50      2.94G     0.3859     0.4441      1.017         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.7it/s 2:55\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.8it/s 5.3s\n","                   all        624        638      0.992      0.972       0.99       0.96\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      24/50      2.96G      0.383     0.4428      1.015         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.7it/s 2:54\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 2.8it/s 7.2s\n","                   all        624        638      0.956      0.976      0.985      0.952\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      25/50      2.97G     0.3776     0.4318      1.011         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.7it/s 2:54\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 4.1it/s 4.9s\n","                   all        624        638      0.978      0.969      0.988      0.955\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      26/50      2.99G     0.3747     0.4319      1.011         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.8it/s 2:53\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.1it/s 6.4s\n","                   all        624        638      0.981      0.969      0.989      0.956\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      27/50      3.01G     0.3678     0.4138      1.007         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.8it/s 2:52\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 4.1it/s 4.8s\n","                   all        624        638      0.993      0.959       0.99      0.955\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      28/50      3.03G     0.3712     0.4181       1.01         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.7it/s 2:55\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 4.1it/s 4.9s\n","                   all        624        638      0.974      0.963      0.983      0.954\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      29/50      3.04G     0.3627     0.4094      1.001         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.8it/s 2:51\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.4it/s 5.9s\n","                   all        624        638       0.96      0.967      0.979      0.949\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      30/50      3.06G     0.3582     0.4022      0.999         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.8it/s 2:52\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.9it/s 5.1s\n","                   all        624        638       0.98      0.977      0.988       0.96\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      31/50      3.08G     0.3548     0.4014     0.9971         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.7it/s 2:56\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.9it/s 5.1s\n","                   all        624        638      0.989      0.954      0.987      0.961\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      32/50      3.09G     0.3569     0.3944      1.001         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.8it/s 2:51\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.3it/s 6.1s\n","                   all        624        638      0.987      0.966      0.987      0.957\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      33/50      3.11G     0.3505     0.3884     0.9975         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.8it/s 2:52\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 4.3it/s 4.7s\n","                   all        624        638      0.995      0.963      0.988      0.962\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      34/50      3.12G     0.3476     0.3758     0.9931         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.7it/s 2:54\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.6it/s 5.5s\n","                   all        624        638      0.987      0.958      0.984      0.955\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      35/50      3.15G     0.3467     0.3798     0.9965         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.7it/s 2:55\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.0it/s 6.7s\n","                   all        624        638      0.989      0.966       0.99      0.964\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      36/50      3.16G     0.3449     0.3732     0.9931         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.8it/s 2:52\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 4.4it/s 4.6s\n","                   all        624        638      0.983      0.969      0.989      0.963\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      37/50      3.18G     0.3404     0.3698     0.9902         15        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.8it/s 2:52\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.1it/s 6.4s\n","                   all        624        638      0.975      0.974      0.987      0.961\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      38/50      3.19G     0.3348     0.3594      0.986         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.8it/s 2:53\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.9it/s 5.1s\n","                   all        624        638      0.985      0.959      0.983      0.955\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      39/50      3.21G     0.3303     0.3567     0.9842         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.7it/s 2:54\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.2it/s 6.2s\n","                   all        624        638      0.987      0.959      0.984      0.959\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      40/50      3.23G     0.3344     0.3578     0.9878          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.7it/s 2:54\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 4.0it/s 5.0s\n","                   all        624        638      0.985      0.967      0.985       0.96\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      41/50      3.25G     0.2383     0.2528     0.9408          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.9it/s 2:48\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.3it/s 6.0s\n","                   all        624        638      0.977       0.97      0.989      0.964\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      42/50      3.26G     0.2325     0.2396     0.9358          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.9it/s 2:44\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.2it/s 6.2s\n","                   all        624        638      0.982      0.986      0.989      0.963\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      43/50      3.28G     0.2267      0.229     0.9312          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.9it/s 2:45\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.2it/s 6.3s\n","                   all        624        638      0.983      0.985      0.989      0.966\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      44/50       3.3G     0.2202     0.2252     0.9316          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.9it/s 2:44\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.3it/s 6.1s\n","                   all        624        638      0.978      0.979      0.989      0.963\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      45/50      3.31G     0.2158     0.2172     0.9237          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.9it/s 2:45\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.3it/s 6.1s\n","                   all        624        638      0.994      0.961      0.988      0.964\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      46/50      3.33G     0.2121     0.2111     0.9218          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.9it/s 2:44\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.4it/s 6.0s\n","                   all        624        638      0.993      0.957      0.988      0.963\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      47/50      3.35G     0.2092     0.2081      0.919          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.9it/s 2:45\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.4it/s 5.8s\n","                   all        624        638       0.98      0.971      0.987      0.961\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      48/50      3.37G     0.2038     0.2022     0.9187          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.9it/s 2:45\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.8it/s 5.3s\n","                   all        624        638      0.994      0.958      0.988      0.962\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      49/50      3.38G     0.2017     0.1991     0.9159          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.9it/s 2:47\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 4.1it/s 4.9s\n","                   all        624        638      0.994      0.961      0.988      0.962\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      50/50       3.4G     0.1973     0.1947     0.9147          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 649/649 3.8it/s 2:49\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.0it/s 6.6s\n","                   all        624        638      0.978      0.978      0.988      0.962\n","\n","50 epochs completed in 2.470 hours.\n","Optimizer stripped from /content/drive/MyDrive/YOLODinero/entrenamiento_billetes2/weights/last.pt, 6.3MB\n","Optimizer stripped from /content/drive/MyDrive/YOLODinero/entrenamiento_billetes2/weights/best.pt, 6.3MB\n","\n","Validating /content/drive/MyDrive/YOLODinero/entrenamiento_billetes2/weights/best.pt...\n","Ultralytics 8.3.228 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n","Model summary (fused): 72 layers, 3,007,793 parameters, 0 gradients, 8.1 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 20/20 3.2it/s 6.2s\n","                   all        624        638      0.983      0.985      0.989      0.966\n","              clp_1000         77         77      0.993          1      0.995      0.993\n","             clp_10000         84         84      0.994          1      0.995      0.992\n","              clp_2000         84         84      0.993          1      0.995      0.992\n","             clp_20000         81         81      0.988          1      0.995      0.993\n","              clp_5000         83         83      0.994          1      0.995      0.993\n","                 usd_1         94         94      0.969      0.991      0.994      0.887\n","                usd_10         24         24      0.999          1      0.995      0.978\n","                usd_20         27         28      0.974      0.929       0.97      0.953\n","                 usd_5         58         59      0.948      0.926      0.965      0.893\n","                usd_50         24         24      0.981          1      0.995      0.982\n","Speed: 0.2ms preprocess, 2.1ms inference, 0.0ms loss, 2.7ms postprocess per image\n","Results saved to \u001b[1m/content/drive/MyDrive/YOLODinero/entrenamiento_billetes2\u001b[0m\n"]}]},{"cell_type":"code","source":["from ultralytics import YOLO\n","\n","model = YOLO(\"/content/drive/MyDrive/YOLODinero/entrenamiento_billetes2/weights/best.pt\")\n"],"metadata":{"id":"fcpZK3WnCubM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","uploaded = files.upload()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":73},"id":"kEUHVTcBC0cx","executionInfo":{"status":"ok","timestamp":1763185563296,"user_tz":180,"elapsed":8050,"user":{"displayName":"HARRY ALBETH RUIZ IPARRAGUIRRE","userId":"09082086999302081748"}},"outputId":"af098b33-4474-4d49-cc9a-1df72599e0a7"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-26c58c3f-0247-4e14-a264-7a72afed2c22\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-26c58c3f-0247-4e14-a264-7a72afed2c22\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving 2000.jpeg to 2000.jpeg\n"]}]},{"cell_type":"code","source":["!yolo export model=\"/content/drive/MyDrive/YOLODinero/entrenamiento_billetes2/weights/best.pt\" format=tflite half=True imgsz=640\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u8l-upk7DXlo","executionInfo":{"status":"ok","timestamp":1763185663232,"user_tz":180,"elapsed":40795,"user":{"displayName":"HARRY ALBETH RUIZ IPARRAGUIRRE","userId":"09082086999302081748"}},"outputId":"c927c865-6771-4204-8c0c-686894cc55cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.228 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n","ğŸ’¡ ProTip: Export to OpenVINO format for best performance on Intel hardware. Learn more at https://docs.ultralytics.com/integrations/openvino/\n","Model summary (fused): 72 layers, 3,007,793 parameters, 0 gradients, 8.1 GFLOPs\n","\n","\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/drive/MyDrive/YOLODinero/entrenamiento_billetes2/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 15, 8400) (6.0 MB)\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1763185628.644162   40587 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1763185628.718632   40587 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","W0000 00:00:1763185629.231657   40587 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1763185629.231698   40587 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1763185629.231703   40587 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1763185629.231707   40587 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['sng4onnx>=1.0.1', 'onnx_graphsurgeon>=0.3.26', 'ai-edge-litert>=1.2.0', 'onnx>=1.12.0,<=1.19.1', 'onnx2tf>=1.26.3', 'onnxslim>=0.1.71', 'onnxruntime'] not found, attempting AutoUpdate...\n","Using Python 3.12.12 environment at: /usr\n","Resolved 20 packages in 2.13s\n","Prepared 11 packages in 4.34s\n","Installed 11 packages in 277ms\n"," + ai-edge-litert==2.0.3\n"," + backports-strenum==1.3.1\n"," + colorama==0.4.6\n"," + coloredlogs==15.0.1\n"," + humanfriendly==10.0\n"," + onnx==1.19.1\n"," + onnx-graphsurgeon==0.5.8\n"," + onnx2tf==1.28.3\n"," + onnxruntime==1.24.0.dev20251031003\n"," + onnxslim==0.1.74\n"," + sng4onnx==1.0.4\n","\n","\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 7.4s\n","WARNING âš ï¸ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n","\n","\n","\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.19.0...\n","\n","\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.1 opset 22...\n","\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.74...\n","\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 2.2s, saved as '/content/drive/MyDrive/YOLODinero/entrenamiento_billetes2/weights/best.onnx' (11.8 MB)\n","\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/calibration_image_sample_data_20x128x128x3_float32.npy.zip to 'calibration_image_sample_data_20x128x128x3_float32.npy.zip': 100% â”â”â”â”â”â”â”â”â”â”â”â” 1.1MB 28.5MB/s 0.0s\n","\u001b[KUnzipping calibration_image_sample_data_20x128x128x3_float32.npy.zip to /content/calibration_image_sample_data_20x128x128x3_float32.npy...: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 52.2files/s 0.0s\n","\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.28.3...\n","Saved artifact at '/content/drive/MyDrive/YOLODinero/entrenamiento_billetes2/weights/best_saved_model'. The following endpoints are available:\n","\n","* Endpoint 'serving_default'\n","  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 640, 640, 3), dtype=tf.float32, name='images')\n","Output Type:\n","  TensorSpec(shape=(1, 15, 8400), dtype=tf.float32, name=None)\n","Captures:\n","  137791227270480: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n","  137791227272208: TensorSpec(shape=(3, 3, 3, 16), dtype=tf.float32, name=None)\n","  137791227272400: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n","  137791227276624: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n","  137791227277008: TensorSpec(shape=(3, 3, 16, 32), dtype=tf.float32, name=None)\n","  137791227275088: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n","  137791227277200: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n","  137791227277392: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n","  137791227278352: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  137791227277968: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  137791227280272: TensorSpec(shape=(3, 3, 16, 16), dtype=tf.float32, name=None)\n","  137791227280848: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n","  137791227277584: TensorSpec(shape=(3, 3, 16, 16), dtype=tf.float32, name=None)\n","  137791227271440: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n","  137791227278928: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  137791227278544: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  137791227281040: TensorSpec(shape=(1, 1, 48, 32), dtype=tf.float32, name=None)\n","  137791227280464: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n","  137791227281232: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n","  137791227279696: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n","  137791227279888: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n","  137790951538768: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n","  137790951539152: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n","  137790951539728: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  137790951539536: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  137790951541648: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n","  137790951541840: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n","  137790951539344: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n","  137790951538960: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n","  137790951541072: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n","  137790951542032: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n","  137790951540688: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n","  137790951542416: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n","  137790951539920: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  137790951540112: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  137790951542800: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n","  137790951542224: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n","  137790951542992: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n","  137790951541264: TensorSpec(shape=(3, 3, 64, 128), dtype=tf.float32, name=None)\n","  137790951542608: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n","  137790951543376: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n","  137790951543568: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n","  137790951544144: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  137790951543952: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  137790951546064: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n","  137790951546256: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n","  137790951543760: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n","  137790951543184: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n","  137790951545488: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n","  137790951546448: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n","  137790951545104: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n","  137790951546832: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n","  137790951544336: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  137790951544528: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  137790951547216: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n","  137790951546640: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n","  137790951547408: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n","  137790951545680: TensorSpec(shape=(3, 3, 128, 256), dtype=tf.float32, name=None)\n","  137790951547024: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n","  137790951547792: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n","  137790951547984: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n","  137790951548560: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  137790951548368: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  137790951550480: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n","  137790951550672: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n","  137790951548176: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n","  137790951547600: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n","  137790951548752: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  137790951548944: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  137790951550864: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n","  137790951549520: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n","  137790951549904: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n","  137790951551248: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n","  137790951550096: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n","  137790951551056: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n","  137790951552016: TensorSpec(shape=(1, 1, 384, 128), dtype=tf.float32, name=None)\n","  137790951552208: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n","  137790951552592: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  137790951551824: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  137790951553936: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n","  137790951554128: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n","  137790951552400: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n","  137790951551440: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n","  137790951553360: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  137790951551632: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  137790951554896: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n","  137790951554704: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n","  137790951553552: TensorSpec(shape=(1, 1, 192, 64), dtype=tf.float32, name=None)\n","  137790951553744: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n","  137790940152272: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  137790940152080: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  137790951553168: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n","  137790940154192: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n","  137790940154384: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n","  137790940153616: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n","  137790940152464: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  137790940152656: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  137790940154768: TensorSpec(shape=(1, 1, 96, 64), dtype=tf.float32, name=None)\n","  137790940154576: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n","  137790940154960: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n","  137790940153232: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n","  137790940151888: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n","  137790940156880: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n","  137790940156304: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n","  137790940158032: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  137790940157840: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  137790940160528: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n","  137790940160720: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n","  137790940160144: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n","  137790940161104: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n","  137790940158416: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  137790940158608: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  137790940159568: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n","  137790940158224: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n","  137790940161296: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n","  137790940157456: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n","  137790940159184: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n","  137790940160912: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n","  137790940162448: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n","  137790940163984: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  137790940163792: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  137790940164368: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n","  137790940165136: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n","  137790940166480: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n","  137790940167056: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n","  137790940164560: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  137790940164944: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n","  137790940166096: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n","  137790940167248: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n","  137790940166864: TensorSpec(shape=(3, 3, 256, 64), dtype=tf.float32, name=None)\n","  137790940166288: TensorSpec(shape=(3, 3, 256, 64), dtype=tf.float32, name=None)\n","  137790940161680: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n","  137790940160336: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n","  137790940155728: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n","  137790940155344: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n","  137790940162640: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n","  137790940166672: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n","  137790940161488: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n","  137790940162064: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n","  137790940153808: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n","  137790940155152: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n","  137790940167824: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n","  137790940165712: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n","  137790940162832: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n","  137790940159760: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n","  137790940156496: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n","  137790940155536: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n","  137790940167440: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n","  137790940167632: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n","  137790940161872: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n","  137790940162256: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n","  137790940156112: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n","  137790940155920: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n","  137790831477200: TensorSpec(shape=(1, 1, 64, 11), dtype=tf.float32, name=None)\n","  137790940165328: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n","  137790940164176: TensorSpec(shape=(1, 1, 64, 11), dtype=tf.float32, name=None)\n","  137790940163408: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n","  137790940157648: TensorSpec(shape=(1, 1, 64, 11), dtype=tf.float32, name=None)\n","  137790940157264: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n","  137790940168016: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n","  137790831476816: TensorSpec(shape=(11,), dtype=tf.float32, name=None)\n","  137790940163216: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n","  137790940163024: TensorSpec(shape=(11,), dtype=tf.float32, name=None)\n","  137790940156688: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n","  137790940157072: TensorSpec(shape=(11,), dtype=tf.float32, name=None)\n","  137790831478160: TensorSpec(shape=(1, 1, 16, 1), dtype=tf.float32, name=None)\n","  137790831477008: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n","  137790831477776: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n","  137790831477392: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n","  137790831479696: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n","  137790831479888: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n","  137790831478736: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n","I0000 00:00:1763185656.772233   40587 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1763185656.772420   40587 single_machine.cc:374] Starting new session\n","W0000 00:00:1763185657.433536   40587 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n","W0000 00:00:1763185657.433576   40587 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n","I0000 00:00:1763185658.272539   40587 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n","I0000 00:00:1763185658.272696   40587 single_machine.cc:374] Starting new session\n","W0000 00:00:1763185658.823946   40587 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n","W0000 00:00:1763185658.823980   40587 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n","\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success âœ… 32.9s, saved as '/content/drive/MyDrive/YOLODinero/entrenamiento_billetes2/weights/best_saved_model' (29.5 MB)\n","\n","\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.19.0...\n","\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success âœ… 0.0s, saved as '/content/drive/MyDrive/YOLODinero/entrenamiento_billetes2/weights/best_saved_model/best_float16.tflite' (5.9 MB)\n","\n","Export complete (33.3s)\n","Results saved to \u001b[1m/content/drive/MyDrive/YOLODinero/entrenamiento_billetes2/weights\u001b[0m\n","Predict:         yolo predict task=detect model=/content/drive/MyDrive/YOLODinero/entrenamiento_billetes2/weights/best_saved_model/best_float16.tflite imgsz=640 half \n","Validate:        yolo val task=detect model=/content/drive/MyDrive/YOLODinero/entrenamiento_billetes2/weights/best_saved_model/best_float16.tflite imgsz=640 data=Reconocimiento-dinero-clp-o-USD-2/data.yaml half \n","Visualize:       https://netron.app\n","ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/export\n"]}]},{"cell_type":"code","source":["!yolo predict model=\"/content/drive/MyDrive/YOLODinero/entrenamiento_billetes2/weights/best_saved_model/best_float16.tflite\" source=0 show=True conf=0.6\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zuniEzZ-Dor4","executionInfo":{"status":"ok","timestamp":1763185706887,"user_tz":180,"elapsed":14579,"user":{"displayName":"HARRY ALBETH RUIZ IPARRAGUIRRE","userId":"09082086999302081748"}},"outputId":"76abead4-7234-4db6-e857-0b75be26c782"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING âš ï¸ Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n","WARNING âš ï¸ Environment does not support cv2.imshow() or PIL Image.show()\n","\n","Ultralytics 8.3.228 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1763185694.737619   40937 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1763185694.743669   40937 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","W0000 00:00:1763185694.760105   40937 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1763185694.760134   40937 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1763185694.760140   40937 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1763185694.760144   40937 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","Loading /content/drive/MyDrive/YOLODinero/entrenamiento_billetes2/weights/best_saved_model/best_float16.tflite for TensorFlow Lite inference...\n","/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n","    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n","    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n","    for details.\n","    \n","  warnings.warn(_INTERPRETER_DELETION_WARNING)\n","INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/yolo\", line 7, in <module>\n","    sys.exit(entrypoint())\n","             ^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/cfg/__init__.py\", line 985, in entrypoint\n","    getattr(model, mode)(**overrides)  # default args from model\n","    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py\", line 540, in predict\n","    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/engine/predictor.py\", line 244, in predict_cli\n","    for _ in gen:  # sourcery skip: remove-empty-nested-block, noqa\n","             ^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\", line 38, in generator_context\n","    response = gen.send(None)\n","               ^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/engine/predictor.py\", line 298, in stream_inference\n","    self.setup_source(source if source is not None else self.args.source)\n","  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/engine/predictor.py\", line 255, in setup_source\n","    self.dataset = load_inference_source(\n","                   ^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/data/build.py\", line 425, in load_inference_source\n","    dataset = LoadStreams(source, vid_stride=vid_stride, buffer=buffer, channels=channels)\n","              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/ultralytics/data/loaders.py\", line 128, in __init__\n","    raise NotImplementedError(\n","NotImplementedError: 'source=0' webcam not supported in Colab and Kaggle notebooks. Try running 'source=0' in a local environment.\n","Sentry is attempting to send 2 pending events\n","Waiting up to 2 seconds\n","Press Ctrl-C to quit\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aon3-JJdzUyI","executionInfo":{"status":"ok","timestamp":1763214997835,"user_tz":180,"elapsed":26572,"user":{"displayName":"HARRY ALBETH RUIZ IPARRAGUIRRE","userId":"09082086999302081748"}},"outputId":"12dba2bf-d8e5-4f97-b5d8-42bfa097e0f0"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["model_path = \"/content/drive/MyDrive/YOLODinero/entrenamiento_billetes2/weights/best_saved_model/best_float16.tflite\"\n","print(\"Modelo listo en:\", model_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zAXjb-UCz72k","executionInfo":{"status":"ok","timestamp":1763215131244,"user_tz":180,"elapsed":29,"user":{"displayName":"HARRY ALBETH RUIZ IPARRAGUIRRE","userId":"09082086999302081748"}},"outputId":"bda74049-b048-472c-a518-41f11352136e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Modelo listo en: /content/drive/MyDrive/YOLODinero/entrenamiento_billetes2/weights/best_saved_model/best_float16.tflite\n"]}]},{"cell_type":"code","source":["from ultralytics import YOLO\n","\n","model = YOLO(\"/content/drive/MyDrive/YOLODinero/entrenamiento_billetes2/weights/best_saved_model/best_float16.tflite\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fuZrKc5-0nLL","executionInfo":{"status":"ok","timestamp":1763215343330,"user_tz":180,"elapsed":8705,"user":{"displayName":"HARRY ALBETH RUIZ IPARRAGUIRRE","userId":"09082086999302081748"}},"outputId":"df6a695d-6591-4f22-8219-75e013912fbb"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Creating new Ultralytics Settings v0.0.6 file âœ… \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","WARNING âš ï¸ Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n"]}]},{"cell_type":"code","source":["from google.colab import files\n","uploaded = files.upload()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":180},"id":"nbvRzvgR11jF","executionInfo":{"status":"ok","timestamp":1763216325137,"user_tz":180,"elapsed":10774,"user":{"displayName":"HARRY ALBETH RUIZ IPARRAGUIRRE","userId":"09082086999302081748"}},"outputId":"34f901d5-dad4-4b20-e09b-60c346b9d3b8"},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-29c9ad47-679c-40cc-96dc-9d29660eb957\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-29c9ad47-679c-40cc-96dc-9d29660eb957\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving 5000.jpeg to 5000.jpeg\n","Saving 2000.jpeg to 2000 (1).jpeg\n","Saving 10000.jpeg to 10000.jpeg\n","Saving 20000.jpeg to 20000.jpeg\n"]}]},{"cell_type":"code","source":["from ultralytics import YOLO\n","from IPython.display import Image, display\n","import glob, os\n","\n","model = YOLO(\"/content/drive/MyDrive/YOLODinero/entrenamiento_billetes2/weights/best_saved_model/best_float16.tflite\")\n","\n","imagenes = [\n","    \"billete 1000.jpeg\",\n","    \"billetes en manos.jpeg\",\n","    \"billetes.jpeg\",\n","    \"billetes10arrugado.jpeg\"\n","]\n","\n","os.makedirs(\"/content/salidas\", exist_ok=True)\n","\n","tabla = []  # para almacenar resultados\n","\n","for img in imagenes:\n","    print(f\"\\nğŸ” Analizando: {img}...\")\n","    results = model.predict(source=img, conf=0.55, save=True)\n","\n","    # ruta de salida con bounding boxes\n","    save_dir = results[0].save_dir\n","    pred_path = f\"{save_dir}/{os.path.basename(img)}\"\n","\n","    # copiar salida si existe\n","    if os.path.exists(pred_path):\n","        destino = f\"/content/salidas/{os.path.basename(img)}\"\n","        os.replace(pred_path, destino)\n","\n","    # obtener detecciones\n","    if len(results[0].boxes) > 0:\n","        for box in results[0].boxes:\n","            cls = results[0].names[int(box.cls)]\n","            conf = float(box.conf)\n","            tabla.append((img, cls, round(conf, 2)))\n","    else:\n","        tabla.append((img, \"âŒ No detectado\", 0))\n","\n","print(\"\\nğŸ“Œ Resultados guardados en /content/salidas\\n\")\n","\n","# Mostrar imÃ¡genes procesadas\n","for img in imagenes:\n","    salida = f\"/content/salidas/{img}\"\n","    if os.path.exists(salida):\n","        display(Image(salida))\n","\n","print(\"\\nğŸ“Œ Detecciones encontradas:\")\n","for fila in tabla:\n","    print(f\"{fila[0]} â†’ {fila[1]} ({fila[2]})\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"preqTlIf18Jn","executionInfo":{"status":"ok","timestamp":1763217467665,"user_tz":180,"elapsed":859,"user":{"displayName":"HARRY ALBETH RUIZ IPARRAGUIRRE","userId":"09082086999302081748"}},"outputId":"1d32e93b-aea6-4bbf-aafb-78f45e08da1c"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING âš ï¸ Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n","\n","ğŸ” Analizando: billete 1000.jpeg...\n","Loading /content/drive/MyDrive/YOLODinero/entrenamiento_billetes2/weights/best_saved_model/best_float16.tflite for TensorFlow Lite inference...\n","\n","image 1/1 /content/billete 1000.jpeg: 640x640 1 clp_1000, 240.4ms\n","Speed: 10.2ms preprocess, 240.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1m/content/runs/detect/predict8\u001b[0m\n","\n","ğŸ” Analizando: billetes en manos.jpeg...\n","\n","image 1/1 /content/billetes en manos.jpeg: 640x640 (no detections), 163.1ms\n","Speed: 4.6ms preprocess, 163.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1m/content/runs/detect/predict8\u001b[0m\n","\n","ğŸ” Analizando: billetes.jpeg...\n","\n","image 1/1 /content/billetes.jpeg: 640x640 1 clp_20000, 136.9ms\n","Speed: 3.3ms preprocess, 136.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1m/content/runs/detect/predict8\u001b[0m\n","\n","ğŸ” Analizando: billetes10arrugado.jpeg...\n","\n","image 1/1 /content/billetes10arrugado.jpeg: 640x640 1 clp_10000, 150.9ms\n","Speed: 6.1ms preprocess, 150.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1m/content/runs/detect/predict8\u001b[0m\n","\n","ğŸ“Œ Resultados guardados en /content/salidas\n","\n","\n","ğŸ“Œ Detecciones encontradas:\n","billete 1000.jpeg â†’ clp_1000 (0.62)\n","billetes en manos.jpeg â†’ âŒ No detectado (0)\n","billetes.jpeg â†’ clp_20000 (0.83)\n","billetes10arrugado.jpeg â†’ clp_10000 (0.87)\n"]}]},{"cell_type":"code","source":["results = model.predict(source=\"billetes en manos.jpeg\", conf=0.45, save=True)\n","results\n"],"metadata":{"id":"Bop5ZAKiAOUR","executionInfo":{"status":"ok","timestamp":1763218352762,"user_tz":180,"elapsed":349,"user":{"displayName":"HARRY ALBETH RUIZ IPARRAGUIRRE","userId":"09082086999302081748"}},"outputId":"c052268a-942f-488a-c52b-d554aca4551b","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/billetes en manos.jpeg: 640x640 (no detections), 308.9ms\n","Speed: 6.2ms preprocess, 308.9ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1m/content/runs/detect/predict8\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["[ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'clp_1000', 1: 'clp_10000', 2: 'clp_2000', 3: 'clp_20000', 4: 'clp_5000', 5: 'usd_1', 6: 'usd_10', 7: 'usd_100', 8: 'usd_20', 9: 'usd_5', 10: 'usd_50'}\n"," obb: None\n"," orig_img: array([[[ 7, 11, 22],\n","         [ 8, 12, 23],\n","         [ 8, 12, 23],\n","         ...,\n","         [23, 42, 55],\n","         [23, 42, 55],\n","         [23, 42, 55]],\n"," \n","        [[ 8, 12, 23],\n","         [ 8, 12, 23],\n","         [ 8, 12, 23],\n","         ...,\n","         [23, 42, 55],\n","         [23, 42, 55],\n","         [23, 42, 55]],\n"," \n","        [[ 8, 12, 23],\n","         [ 8, 12, 23],\n","         [ 6, 12, 23],\n","         ...,\n","         [22, 41, 54],\n","         [22, 41, 54],\n","         [22, 41, 54]],\n"," \n","        ...,\n"," \n","        [[41, 46, 55],\n","         [42, 47, 56],\n","         [40, 45, 54],\n","         ...,\n","         [27, 49, 55],\n","         [27, 49, 55],\n","         [27, 49, 55]],\n"," \n","        [[40, 45, 54],\n","         [42, 47, 56],\n","         [40, 45, 54],\n","         ...,\n","         [28, 50, 56],\n","         [28, 50, 56],\n","         [28, 50, 56]],\n"," \n","        [[40, 45, 54],\n","         [42, 47, 56],\n","         [39, 44, 53],\n","         ...,\n","         [28, 50, 56],\n","         [28, 50, 56],\n","         [28, 50, 56]]], dtype=uint8)\n"," orig_shape: (164, 308)\n"," path: '/content/billetes en manos.jpeg'\n"," probs: None\n"," save_dir: '/content/runs/detect/predict8'\n"," speed: {'preprocess': 6.245710000257532, 'inference': 308.8933039998665, 'postprocess': 3.583753000384604}]"]},"metadata":{},"execution_count":29}]}]}